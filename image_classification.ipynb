{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 0\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x/255.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Look into LabelBinarizer in the preprocessing module of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return to_categorical(x, num_classes=10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers.\n",
    "\n",
    "** Hint: **\n",
    "\n",
    "When unpacking values as an argument in Python, look into the [unpacking](https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists) operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    _ ,input_height, input_width, input_depth = x_tensor.get_shape()\n",
    "    kernel_height, kernel_width = conv_ksize\n",
    "\n",
    "    kernel_weight = tf.Variable(tf.random_normal([kernel_height, kernel_width, \n",
    "                                                     int(input_depth), conv_num_outputs]))\n",
    "    kernel_bias = tf.Variable(tf.random_normal([conv_num_outputs]))\n",
    "    strides = [1,conv_strides[0], conv_strides[1], 1]\n",
    "    padding = 'SAME'\n",
    "\n",
    "    conv2d_layer = tf.nn.conv2d(x_tensor, kernel_weight, strides, padding)\n",
    "    conv2d_layer = tf.nn.bias_add(conv2d_layer, kernel_bias)\n",
    "    conv2d_layer = tf.nn.relu(conv2d_layer)\n",
    "    conv2d_maxpool_layer = tf.nn.max_pool(conv2d_layer, \n",
    "                                          ksize=[1,pool_ksize[0],pool_ksize[1],1], \n",
    "                                          strides=[1,pool_strides[0],pool_strides[1],1], \n",
    "                                          padding='SAME')\n",
    "    return conv2d_maxpool_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    tensor_shape =x_tensor.get_shape().as_list()\n",
    "    flatten_shape = np.prod(np.array(tensor_shape[1:]))\n",
    "    return tf.reshape(x_tensor, [-1, flatten_shape])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    tensor_weights = tf.Variable(tf.random_normal([tensor_shape[1], num_outputs]))\n",
    "    tensor_bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    \n",
    "    fully_conn_layer = tf.add(tf.matmul(x_tensor, tensor_weights), tensor_bias)\n",
    "    fully_conn_layer = tf.nn.relu(fully_conn_layer)\n",
    "    \n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    tensor_weights = tf.Variable(tf.random_normal([tensor_shape[1], num_outputs]))\n",
    "    tensor_bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(x_tensor, tensor_weights), tensor_bias)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 32, (5, 5), (1, 1), (2, 2), (2, 2))\n",
    "    conv2 = conv2d_maxpool(conv1, 300, (5, 5), (1, 1), (2, 2), (2, 2))\n",
    "    #conv3 = conv2d_maxpool(conv1, 256, (5, 5), (1, 1), (2, 2), (2, 2))\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten1 = flatten(conv2)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_conn1 = fully_conn(flatten1, 2000)\n",
    "    fully_conn1 = tf.nn.dropout(fully_conn1, keep_prob)\n",
    "    \n",
    "    fully_conn2 = fully_conn(fully_conn1, 2000)\n",
    "    fully_conn2 = tf.nn.dropout(fully_conn2, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output1 = output(fully_conn2, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    print ('Loss is {} Valid accuracy is {}'.format(loss, valid_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss is 5414127.0 Valid accuracy is 0.15594059228897095\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss is 3248810.25 Valid accuracy is 0.2487623691558838\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss is 1947367.375 Valid accuracy is 0.2883663475513458\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss is 1385281.875 Valid accuracy is 0.3279702663421631\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss is 878940.25 Valid accuracy is 0.30816829204559326\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss is 612971.25 Valid accuracy is 0.323019802570343\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss is 403643.875 Valid accuracy is 0.323019802570343\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss is 283051.96875 Valid accuracy is 0.320544570684433\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss is 198391.4375 Valid accuracy is 0.28094059228897095\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss is 141591.15625 Valid accuracy is 0.2599009871482849\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss is 103005.6796875 Valid accuracy is 0.22648513317108154\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss is 76022.0234375 Valid accuracy is 0.20049503445625305\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss is 58212.27734375 Valid accuracy is 0.19059404730796814\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss is 45075.359375 Valid accuracy is 0.18069306015968323\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss is 36623.5 Valid accuracy is 0.18193069100379944\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss is 30380.357421875 Valid accuracy is 0.17202970385551453\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss is 25583.474609375 Valid accuracy is 0.16460394859313965\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss is 21244.365234375 Valid accuracy is 0.17202970385551453\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss is 17904.5 Valid accuracy is 0.1695544570684433\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss is 14833.8515625 Valid accuracy is 0.1683168262243271\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss is 12297.015625 Valid accuracy is 0.16584157943725586\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss is 10757.1748046875 Valid accuracy is 0.15717822313308716\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss is 9399.4365234375 Valid accuracy is 0.16212871670722961\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss is 7864.80810546875 Valid accuracy is 0.16336634755134583\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss is 6854.490234375 Valid accuracy is 0.16212871670722961\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss is 6049.998046875 Valid accuracy is 0.1608910858631134\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss is 5370.87744140625 Valid accuracy is 0.15346534550189972\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss is 4854.482421875 Valid accuracy is 0.15470296144485474\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss is 4309.13037109375 Valid accuracy is 0.1522277146577835\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss is 3872.486572265625 Valid accuracy is 0.14727723598480225\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss is 3437.18603515625 Valid accuracy is 0.14727722108364105\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss is 3069.154296875 Valid accuracy is 0.143564373254776\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss is 2651.76416015625 Valid accuracy is 0.1435643434524536\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss is 2313.9482421875 Valid accuracy is 0.14108911156654358\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss is 2063.470703125 Valid accuracy is 0.14108911156654358\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss is 1848.1484375 Valid accuracy is 0.14108911156654358\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss is 1610.135009765625 Valid accuracy is 0.14108911156654358\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss is 1342.8525390625 Valid accuracy is 0.14108911156654358\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss is 1165.3818359375 Valid accuracy is 0.14480197429656982\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss is 1061.281494140625 Valid accuracy is 0.14480197429656982\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss is 945.5783081054688 Valid accuracy is 0.11881187558174133\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss is 823.691162109375 Valid accuracy is 0.12128712236881256\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss is 711.2950439453125 Valid accuracy is 0.11881189048290253\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss is 581.4383544921875 Valid accuracy is 0.12004950642585754\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss is 510.7591247558594 Valid accuracy is 0.14108909666538239\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss is 430.9967346191406 Valid accuracy is 0.13861384987831116\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss is 378.0517883300781 Valid accuracy is 0.1150989979505539\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss is 334.638671875 Valid accuracy is 0.1150989979505539\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss is 305.4281005859375 Valid accuracy is 0.11509901285171509\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss is 269.44989013671875 Valid accuracy is 0.13985148072242737\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss is 249.45201110839844 Valid accuracy is 0.13985148072242737\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss is 231.26751708984375 Valid accuracy is 0.13861386477947235\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss is 214.59765625 Valid accuracy is 0.13861386477947235\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss is 201.5785369873047 Valid accuracy is 0.11509900540113449\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss is 183.64871215820312 Valid accuracy is 0.11262375116348267\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss is 164.1912384033203 Valid accuracy is 0.11138612776994705\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss is 139.57077026367188 Valid accuracy is 0.11262375116348267\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss is 129.86192321777344 Valid accuracy is 0.11262375116348267\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss is 127.98958587646484 Valid accuracy is 0.13613861799240112\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss is 128.5460205078125 Valid accuracy is 0.13613860309123993\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss is 108.33196258544922 Valid accuracy is 0.13613861799240112\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss is 99.38762664794922 Valid accuracy is 0.13737623393535614\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss is 113.84872436523438 Valid accuracy is 0.1349009871482849\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss is 110.47427368164062 Valid accuracy is 0.1349009871482849\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss is 71.85700988769531 Valid accuracy is 0.13613860309123993\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss is 63.98815155029297 Valid accuracy is 0.11262375116348267\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss is 57.70017623901367 Valid accuracy is 0.13613861799240112\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss is 47.40861892700195 Valid accuracy is 0.13613861799240112\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss is 41.91434097290039 Valid accuracy is 0.13613860309123993\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss is 40.454891204833984 Valid accuracy is 0.13613861799240112\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss is 44.62162399291992 Valid accuracy is 0.11262375116348267\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss is 48.33030319213867 Valid accuracy is 0.11262375116348267\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss is 50.00642776489258 Valid accuracy is 0.1336633712053299\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss is 46.47303009033203 Valid accuracy is 0.13242574036121368\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss is 49.47259521484375 Valid accuracy is 0.12995049357414246\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss is 37.54762268066406 Valid accuracy is 0.12995049357414246\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss is 36.13215637207031 Valid accuracy is 0.12995049357414246\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss is 26.762659072875977 Valid accuracy is 0.12871286273002625\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss is 47.39408493041992 Valid accuracy is 0.12871286273002625\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss is 52.35344696044922 Valid accuracy is 0.12871287763118744\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss is 38.615325927734375 Valid accuracy is 0.12747524678707123\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss is 11.006139755249023 Valid accuracy is 0.12871286273002625\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss is 10.358386993408203 Valid accuracy is 0.12871287763118744\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss is 19.566364288330078 Valid accuracy is 0.10767325758934021\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss is 14.571247100830078 Valid accuracy is 0.12871286273002625\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss is 10.836357116699219 Valid accuracy is 0.12747524678707123\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss is 9.226566314697266 Valid accuracy is 0.12871286273002625\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss is 7.71996545791626 Valid accuracy is 0.10643564164638519\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss is 5.741979598999023 Valid accuracy is 0.1076732724905014\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss is 5.4728851318359375 Valid accuracy is 0.12995049357414246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, CIFAR-10 Batch 1:  Loss is 5.221134185791016 Valid accuracy is 0.12995049357414246\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss is 5.163052082061768 Valid accuracy is 0.12995049357414246\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss is 5.237728118896484 Valid accuracy is 0.12995049357414246\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss is 5.384164810180664 Valid accuracy is 0.10767325758934021\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss is 5.104538917541504 Valid accuracy is 0.12995049357414246\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss is 4.444266319274902 Valid accuracy is 0.12995049357414246\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss is 49.33355712890625 Valid accuracy is 0.12747524678707123\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss is 35.25825119018555 Valid accuracy is 0.10396037995815277\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss is 33.4283561706543 Valid accuracy is 0.10148514062166214\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss is 41.50944900512695 Valid accuracy is 0.10024750977754593\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss is 33.28423309326172 Valid accuracy is 0.12376236915588379\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss is 17.49468994140625 Valid accuracy is 0.12376236915588379\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss is 25.504642486572266 Valid accuracy is 0.125\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss is 27.852035522460938 Valid accuracy is 0.12376236915588379\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss is 24.124879837036133 Valid accuracy is 0.12376236915588379\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss is 21.474946975708008 Valid accuracy is 0.12376236915588379\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss is 15.48169231414795 Valid accuracy is 0.12376236915588379\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss is 30.207496643066406 Valid accuracy is 0.12252474576234818\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss is 29.336318969726562 Valid accuracy is 0.12128712236881256\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss is 30.514328002929688 Valid accuracy is 0.12004950642585754\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss is 22.141220092773438 Valid accuracy is 0.09529702365398407\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss is 20.703405380249023 Valid accuracy is 0.12004949897527695\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss is 12.803552627563477 Valid accuracy is 0.12004949897527695\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss is 3.2788641452789307 Valid accuracy is 0.11881187558174133\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss is 2.7410662174224854 Valid accuracy is 0.12004950642585754\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss is 2.673910140991211 Valid accuracy is 0.12004950642585754\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss is 2.6385459899902344 Valid accuracy is 0.12004950642585754\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss is 2.6957833766937256 Valid accuracy is 0.12004949897527695\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss is 2.690758466720581 Valid accuracy is 0.11881187558174133\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss is 2.673585891723633 Valid accuracy is 0.11881187558174133\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss is 2.6794703006744385 Valid accuracy is 0.11881186813116074\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss is 2.7014377117156982 Valid accuracy is 0.11881189048290253\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss is 2.7065420150756836 Valid accuracy is 0.11881189048290253\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss is 2.696333885192871 Valid accuracy is 0.11881187558174133\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss is 2.671215772628784 Valid accuracy is 0.11757424473762512\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss is 2.6331684589385986 Valid accuracy is 0.11757424473762512\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss is 2.680037260055542 Valid accuracy is 0.11757425963878632\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss is 2.6188113689422607 Valid accuracy is 0.11757424473762512\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss is 4.48958683013916 Valid accuracy is 0.09158415347337723\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss is 14.49702262878418 Valid accuracy is 0.09158414602279663\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss is 16.868120193481445 Valid accuracy is 0.11757424473762512\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss is 14.190579414367676 Valid accuracy is 0.11757425963878632\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss is 12.991832733154297 Valid accuracy is 0.11757425218820572\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss is 12.453298568725586 Valid accuracy is 0.11757425218820572\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss is 6.035128593444824 Valid accuracy is 0.11757425963878632\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss is 2.601720094680786 Valid accuracy is 0.11757425218820572\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss is 2.593569278717041 Valid accuracy is 0.11757425218820572\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss is 2.5245628356933594 Valid accuracy is 0.11757424473762512\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss is 2.5200555324554443 Valid accuracy is 0.11757425963878632\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss is 2.526214122772217 Valid accuracy is 0.11757425218820572\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss is 2.4725990295410156 Valid accuracy is 0.11757424473762512\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss is 2.589150905609131 Valid accuracy is 0.11757424473762512\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss is 2.59686279296875 Valid accuracy is 0.11757425218820572\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss is 2.5218539237976074 Valid accuracy is 0.09158415347337723\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss is 2.588508129119873 Valid accuracy is 0.09158414602279663\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss is 2.587461233139038 Valid accuracy is 0.11757424473762512\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss is 2.589395523071289 Valid accuracy is 0.11757424473762512\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss is 2.570417881011963 Valid accuracy is 0.11757425963878632\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss is 2.5321855545043945 Valid accuracy is 0.11757425218820572\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss is 2.565722942352295 Valid accuracy is 0.11757424473762512\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss is 2.601759672164917 Valid accuracy is 0.11757424473762512\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss is 2.5567729473114014 Valid accuracy is 0.11757424473762512\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss is 2.5197880268096924 Valid accuracy is 0.11757425963878632\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss is 8.241883277893066 Valid accuracy is 0.11757425218820572\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss is 7.985873699188232 Valid accuracy is 0.11757425963878632\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss is 2.474315643310547 Valid accuracy is 0.11757425218820572\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss is 2.5206120014190674 Valid accuracy is 0.11757424473762512\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss is 2.5172810554504395 Valid accuracy is 0.09158415347337723\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss is 2.5031211376190186 Valid accuracy is 0.11757425218820572\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss is 2.5052123069763184 Valid accuracy is 0.11757425963878632\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss is 4.578981399536133 Valid accuracy is 0.11757424473762512\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss is 11.926506996154785 Valid accuracy is 0.1163366287946701\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss is 14.752614974975586 Valid accuracy is 0.1163366287946701\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss is 15.837646484375 Valid accuracy is 0.1163366287946701\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss is 16.231693267822266 Valid accuracy is 0.1163366287946701\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss is 16.45695686340332 Valid accuracy is 0.1163366287946701\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss is 16.5224609375 Valid accuracy is 0.11633662134408951\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss is 16.46641731262207 Valid accuracy is 0.1163366287946701\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss is 16.397804260253906 Valid accuracy is 0.1163366287946701\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss is 11.243553161621094 Valid accuracy is 0.1163366287946701\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss is 2.4915592670440674 Valid accuracy is 0.1150989979505539\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss is 2.470903158187866 Valid accuracy is 0.11509900540113449\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss is 2.482513427734375 Valid accuracy is 0.11509900540113449\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss is 2.4436116218566895 Valid accuracy is 0.11509900540113449\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss is 2.450477361679077 Valid accuracy is 0.11509901285171509\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss is 2.4438321590423584 Valid accuracy is 0.11509900540113449\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss is 2.5021510124206543 Valid accuracy is 0.1150989979505539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178, CIFAR-10 Batch 1:  Loss is 2.4554781913757324 Valid accuracy is 0.1163366287946701\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss is 2.4397823810577393 Valid accuracy is 0.1163366287946701\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss is 2.4267771244049072 Valid accuracy is 0.1163366287946701\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss is 2.4412941932678223 Valid accuracy is 0.11509901285171509\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss is 2.4726598262786865 Valid accuracy is 0.11509900540113449\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss is 2.393602132797241 Valid accuracy is 0.11509901285171509\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss is 2.414360523223877 Valid accuracy is 0.11509900540113449\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss is 2.4387216567993164 Valid accuracy is 0.1150989979505539\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss is 2.3953065872192383 Valid accuracy is 0.11509900540113449\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss is 2.387908935546875 Valid accuracy is 0.1150989979505539\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss is 2.4109132289886475 Valid accuracy is 0.11509900540113449\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss is 2.416666269302368 Valid accuracy is 0.1150989979505539\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss is 2.3850603103637695 Valid accuracy is 0.11509900540113449\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss is 2.4075546264648438 Valid accuracy is 0.11509901285171509\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss is 2.4324777126312256 Valid accuracy is 0.11509901285171509\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss is 2.397777795791626 Valid accuracy is 0.1150989979505539\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss is 2.4027493000030518 Valid accuracy is 0.1150989979505539\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss is 2.373598575592041 Valid accuracy is 0.11509901285171509\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss is 2.3894338607788086 Valid accuracy is 0.1150989979505539\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss is 2.4154045581817627 Valid accuracy is 0.1150989979505539\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss is 2.382293701171875 Valid accuracy is 0.1150989979505539\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss is 2.3758225440979004 Valid accuracy is 0.1150989979505539\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss is 2.407635450363159 Valid accuracy is 0.11509900540113449\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. That's because there are many more techniques that can be applied to your model and we recemmond that once you are done with this project, you explore!\n",
    "\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
